<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!-- Put site-specific property overrides in this file. -->
<configuration>
  <property>
    <name>dfs.replication</name>
    <value>3</value>
  </property>
  <property>
    <name>dfs.permissions</name>
    <value>true</value>
  </property>
  <property>
    <!-- specify this so that running 'hadoop namenode -format' formats the right dir -->
    <name>dfs.name.dir</name>
    <value>/data/hadoop/cache/dfs/name,/data/hadoop/cache/dfs/name_bak</value>
  </property>
  <!--  <property>
	<name>dfs.host.exclude</name>
	<value>/etc/hadoop/conf/slaves.ex</value>
  </property>-->
  <property>
    <name>topology.script.file.name</name>
    <value>/opt/hadoop/conf/rack.sh</value>
  </property>
  <property>
    <name>topology.script.number.args</name>
    <value>1000</value>
    <description> The max number of args that the script configured with
    topology.script.file.name should be run with. Each arg is an
    IP address.
    </description>
  </property>
  <property>
    <name>fs.checkpoint.dir</name>
    <value>/data/namesecondary,/data1/namesecondary</value>
    <final>true</final>
  </property>
  <property>
    <name>dfs.data.dir</name>
    <value>/data/hadoop/data,/data1/hadoop/data</value>
    <description>Determines where on the local filesystem an DFS data node
      should store its blocks.  If this is a comma-delimited
      list of directories, then data will be stored in all named
      directories, typically on different devices.
      Directories that do not exist are ignored.
    </description>
  </property>
  <property>
    <name>dfs.balance.bandwidthPerSec</name>
    <value>42914560</value>
    <description>  Specifies the maximum bandwidth that each datanode can utilize for the balancing purpose in term of the number of bytes per second. </description>
  </property>
  <property>
    <name>dfs.namenode.plugins</name>
    <value>org.apache.hadoop.thriftfs.NamenodePlugin</value>
    <description>Comma-separated list of namenode plug-ins to be activated.
</description>
  </property>
  <property>
    <name>dfs.datanode.plugins</name>
    <value>org.apache.hadoop.thriftfs.DatanodePlugin</value>
    <description>Comma-separated list of datanode plug-ins to be activated.
</description>
  </property>
  <property>
    <name>dfs.thrift.address</name>
    <value>0.0.0.0:9090</value>
  </property>
  <property>
    <name>dfs.datanode.socket.write.timeout</name>
    <value>0</value>
  </property>
  <property>
    <name>dfs.datanode.max.xcievers</name>
    <value>1024</value>
  </property>
  <property>
    <name>dfs.secondary.http.address</name>
    <value>eflag-hadoop7.d.eflagcomm.com:50090</value>
    <description>
    The secondary namenode http server address and port.
    If the port is 0 then the server will start on a free port.
  </description>
  </property>
  <property>
  <name>dfs.http.address</name>
  <value>eflag-hadoop6.d.eflagcomm.com:50070</value>
  <description>
  The address and the base port where the dfs namenode web ui will listen on.
  If the port is 0 then the server will start on a free port.
  </description>
  </property>
  <property>
    <name>dfs.support.append</name>
    <value>true</value>
   </property>
</configuration>
